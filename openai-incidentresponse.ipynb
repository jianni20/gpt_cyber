{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incident Response Playbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_incident_response_playbook(threat_type, environment_details):\n",
    "    \"\"\"\n",
    "    Generate an incident response playbook based on the provided threat type and environment details.\n",
    "    \"\"\"\n",
    "    # Create the messages for the OpenAI API\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assistant helping to create an incident response playbook.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Create a detailed incident response playbook for handling a '{threat_type}' threat affecting the following environment: {environment_details}.\"}\n",
    "    ]\n",
    "\n",
    "    # Make the API call\n",
    "    try:\n",
    "        client = OpenAI() # Updated for the new OpenAI API\n",
    "        response = client.chat.completions.create( # Use the new OpenAI API client to interact with ChatGPT\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=2048,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        response_content = response.choices[0].message.content.strip() # Updated for the new OpenAI API\n",
    "        return response_content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input from the user\n",
    "threat_type = input(\"Enter the threat type: \")\n",
    "environment_details = input(\"Enter environment details: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the playbook\n",
    "playbook = generate_incident_response_playbook(threat_type, environment_details)\n",
    "\n",
    "# Print the generated playbook\n",
    "if playbook:\n",
    "    print(\"\\nGenerated Incident Response Playbook:\")\n",
    "    print(playbook)\n",
    "else:\n",
    "    print(\"Failed to generate the playbook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI  # Updated for the new OpenAI API\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import faiss  # Make sure FAISS is installed\n",
    "\n",
    "client = OpenAI()  # Updated for the new OpenAI API\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_log_to_json(raw_log_path):\n",
    "    #Parses a raw log file and converts it into a JSON format.\n",
    "    # Regular expressions to match timestamps and event descriptions in the raw log\n",
    "    timestamp_regex = r'\\[\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\]'\n",
    "    event_regex = r'Event: (.+)'\n",
    "\n",
    "    json_data = []\n",
    "\n",
    "    with open(raw_log_path, 'r') as file:\n",
    "        for line in file:\n",
    "            timestamp_match = re.search(timestamp_regex, line)\n",
    "            event_match = re.search(event_regex, line)\n",
    "\n",
    "            if timestamp_match and event_match:\n",
    "                timestamp = timestamp_match.group().strip('[]')\n",
    "                event_description = event_match.group(1)\n",
    "                json_data.append({\"Timestamp\": timestamp, \"Event\": event_description})\n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        response = client.embeddings.create(\n",
    "            input=text,\n",
    "            model=\"text-embedding-ada-002\"  # Adjust the model as needed\n",
    "        )\n",
    "        try:\n",
    "            # Attempt to access the embedding as if the response is a dictionary\n",
    "            embedding = response['data'][0]['embedding']\n",
    "        except TypeError:\n",
    "            # If the above fails, access the embedding assuming 'response' is an object with attributes\n",
    "            embedding = response.data[0].embedding\n",
    "\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faiss_index(embeddings):\n",
    "    # Creates a FAISS index for a given set of embeddings.\n",
    "    d = embeddings.shape[1]  # Dimensionality of the embeddings\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(embeddings.astype(np.float32))  # FAISS expects float32\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_logs_with_embeddings(log_data):\n",
    "    # Define your templates and compute their embeddings\n",
    "    suspicious_templates = [\"Unauthorized access attempt detected\", \"Multiple failed login attempts\"]\n",
    "    normal_templates = [\"User logged in successfully\", \"System health check completed\"]\n",
    "    suspicious_embeddings = get_embeddings(suspicious_templates)\n",
    "    normal_embeddings = get_embeddings(normal_templates)\n",
    "\n",
    "    # Combine all template embeddings and create a FAISS index\n",
    "    template_embeddings = np.vstack((suspicious_embeddings, normal_embeddings))\n",
    "    index = create_faiss_index(template_embeddings)\n",
    "\n",
    "    # Labels for each template\n",
    "    labels = ['Suspicious'] * len(suspicious_embeddings) + ['Normal'] * len(normal_embeddings)\n",
    "\n",
    "    categorized_events = []\n",
    "\n",
    "    for entry in log_data:\n",
    "        # Fetch the embedding for the current log entry\n",
    "        log_embedding = get_embeddings([entry[\"Event\"]]).astype(np.float32)\n",
    "\n",
    "        # Perform the nearest neighbor search with FAISS\n",
    "        k = 1  # Number of nearest neighbors to find\n",
    "        _, indices = index.search(log_embedding, k)\n",
    "\n",
    "        # Determine the category based on the nearest template\n",
    "        category = labels[indices[0][0]]\n",
    "        categorized_events.append((entry[\"Timestamp\"], entry[\"Event\"], category))\n",
    "\n",
    "    return categorized_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample raw log file path\n",
    "raw_log_file_path = 'sample_log_file.txt'\n",
    "\n",
    "# Parse the raw log file into JSON format\n",
    "log_data = parse_raw_log_to_json(raw_log_file_path)\n",
    "\n",
    "# Analyze the logs\n",
    "categorized_timeline = analyze_logs_with_embeddings(log_data)\n",
    "\n",
    "# Print the categorized timeline\n",
    "for timestamp, event, category in categorized_timeline:\n",
    "    print(f\"{timestamp} - {event} - {category}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-cyber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
